{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b95750c",
   "metadata": {},
   "source": [
    "# 03 — Model Training & Evaluation\n",
    "**Urban Energy Consumption Forecasting with LSTM**\n",
    "\n",
    "This notebook trains the stacked LSTM, tracks learning curves, and runs a\n",
    "comprehensive evaluation on the held-out test set.\n",
    "\n",
    "Sections\n",
    "1. Environment & data preparation\n",
    "2. Model architecture overview\n",
    "3. Training\n",
    "4. Learning curves\n",
    "5. Test-set metrics\n",
    "6. Prediction visualisations\n",
    "7. Horizon error profile\n",
    "8. Comparison against ARIMA baseline\n",
    "9. Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, warnings, os\n",
    "sys.path.insert(0, '..')\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from config import (\n",
    "    RAW_DATA_FILE, MODEL_SAVE_PATH, LOOKBACK, HORIZON,\n",
    "    EPOCHS, BATCH_SIZE, LEARNING_RATE, FEATURE_COLUMNS\n",
    ")\n",
    "from src.preprocess import DataPreprocessor\n",
    "from src.model import build_lstm_model, train_model\n",
    "from src.evaluate import ModelEvaluator, compute_all_metrics\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams.update({'figure.dpi': 120})\n",
    "\n",
    "print(f'TensorFlow {tf.__version__}')\n",
    "print(f'GPUs: {tf.config.list_physical_devices(\"GPU\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fbb79",
   "metadata": {},
   "source": [
    "## 1 · Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da18742",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = DataPreprocessor(lookback=LOOKBACK, horizon=HORIZON)\n",
    "splits = prep.run(raw_filepath=RAW_DATA_FILE, save=True)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = splits\n",
    "\n",
    "print(f'X_train : {X_train.shape}')\n",
    "print(f'X_val   : {X_val.shape}')\n",
    "print(f'X_test  : {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3fbc7",
   "metadata": {},
   "source": [
    "## 2 · Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749712de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[2]\n",
    "model = build_lstm_model(\n",
    "    n_features=n_features,\n",
    "    lookback=LOOKBACK,\n",
    "    horizon=HORIZON,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4414ff81",
   "metadata": {},
   "source": [
    "## 3 · Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(\n",
    "    model=model,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val,     y_val=y_val,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_path=MODEL_SAVE_PATH,\n",
    ")\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4853d",
   "metadata": {},
   "source": [
    "## 4 · Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "epochs_ran = range(1, len(hist['loss']) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "axes[0].plot(epochs_ran, hist['loss'],     label='Train Loss',  color='steelblue')\n",
    "axes[0].plot(epochs_ran, hist['val_loss'], label='Val Loss',    color='darkorange', linestyle='--')\n",
    "axes[0].set_title('MSE Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(epochs_ran, hist['mae'],     label='Train MAE',  color='steelblue')\n",
    "axes[1].plot(epochs_ran, hist['val_mae'], label='Val MAE',    color='darkorange', linestyle='--')\n",
    "axes[1].set_title('Mean Absolute Error')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE (scaled)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_epoch = np.argmin(hist['val_loss']) + 1\n",
    "print(f'Best epoch: {best_epoch}  |  val_loss = {min(hist[\"val_loss\"]):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f76f7",
   "metadata": {},
   "source": [
    "## 5 · Test-Set Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(model=model, preprocessor=prep)\n",
    "metrics = evaluator.evaluate(X_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a2e91",
   "metadata": {},
   "source": [
    "## 6 · Prediction Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluator.plot_predictions(X_test, y_test, n_samples=336)  # 2-week window\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099edbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluator.plot_residuals(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c3399",
   "metadata": {},
   "source": [
    "## 7 · Horizon Error Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa645aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluator.plot_horizon_errors(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4e891",
   "metadata": {},
   "source": [
    "## 8 · Comparison Against Persistence Baseline\n",
    "\n",
    "A naive persistence model predicts the next 24h to be identical to the previous 24h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_kw = prep.inverse_scale_y(y_test)\n",
    "y_pred_kw = evaluator.predict(X_test)\n",
    "\n",
    "# Persistence: y_pred = last observed value repeated HORIZON times\n",
    "# Use the last step of the input window as the naïve forecast\n",
    "X_test_orig_power = prep.scaler_X.inverse_transform(\n",
    "    X_test[:, -1, :]\n",
    ")[:, 0]   # power column\n",
    "\n",
    "y_persist = np.tile(X_test_orig_power[:, np.newaxis], (1, HORIZON))\n",
    "\n",
    "lstm_metrics  = compute_all_metrics(y_test_kw.ravel(), y_pred_kw.ravel())\n",
    "naive_metrics = compute_all_metrics(y_test_kw.ravel(), y_persist.ravel())\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'LSTM (ours)': lstm_metrics,\n",
    "    'Persistence baseline': naive_metrics\n",
    "}).T\n",
    "\n",
    "print('\\n--- Model Comparison ---')\n",
    "display(comparison.round(4))\n",
    "\n",
    "improvement = (1 - lstm_metrics['MAE'] / naive_metrics['MAE']) * 100\n",
    "print(f'\\nLSTM reduces MAE by {improvement:.1f}% over the persistence baseline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea518b73",
   "metadata": {},
   "source": [
    "## 9 · Export\n",
    "\n",
    "The best checkpoint was already saved automatically during training.  Here we confirm the path and display the file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if MODEL_SAVE_PATH.exists():\n",
    "    size_mb = MODEL_SAVE_PATH.stat().st_size / 1e6\n",
    "    print(f'Model saved at : {MODEL_SAVE_PATH}')\n",
    "    print(f'File size      : {size_mb:.2f} MB')\n",
    "else:\n",
    "    print('Model file not found — training may not have completed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66253191",
   "metadata": {},
   "source": [
    "## 10 · Summary\n",
    "\n",
    "| Metric | LSTM | Persistence |\n",
    "|--------|------|-------------|\n",
    "| MAE    | see cell above | see cell above |\n",
    "| RMSE   | see cell above | see cell above |\n",
    "| R²     | see cell above | see cell above |\n",
    "\n",
    "The trained model is ready for deployment via `serve.py` (FastAPI).\n",
    "\n",
    "```bash\n",
    "python serve.py  # starts the REST endpoint on port 8000\n",
    "```\n",
    "\n",
    "Or with Docker:\n",
    "\n",
    "```bash\n",
    "docker compose --profile serve up api\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
